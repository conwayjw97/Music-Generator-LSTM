{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOWIe+GzeQ1XRpn7+InK3M/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conwayjw97/Music-Generator-LSTM/blob/master/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWllAAQIxXW5",
        "colab_type": "text"
      },
      "source": [
        "# [Tutorial Link](https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcWeBbDA4VQD",
        "colab_type": "text"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns6tg9sY4UuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "from music21 import converter, instrument, note, chord\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, Input\n",
        "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvA1gbK67qjZ",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z15jB5l27105",
        "colab_type": "code",
        "outputId": "707ebaf8-47ce-4610-9f36-f52d67b27ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Initialise empty repository to pull data into\n",
        "!git init \n",
        "# Add the remote origin\n",
        "!git remote add origin -f https://github.com/Skuldur/Classical-Piano-Composer.git\n",
        "# Reset the HEAD in case a different folder was already pulled\n",
        "!git reset --hard HEAD\n",
        "!git clean -f -d\n",
        "# Tell git we are checking out specific folders\n",
        "!git config core.sparsecheckout true\n",
        "# Recursively checkout the needed folders\n",
        "!echo \"data/*\" >> .git/info/sparse-checkout\n",
        "!echo \"midi_songs/*\" >> .git/info/sparse-checkout\n",
        "!echo \"weights.hdf5\" >> .git/info/sparse-checkout\n",
        "# Pull dataset from repositoryF\n",
        "!git pull origin master"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "Updating origin\n",
            "remote: Enumerating objects: 334, done.\u001b[K\n",
            "remote: Total 334 (delta 0), reused 0 (delta 0), pack-reused 334\u001b[K\n",
            "Receiving objects: 100% (334/334), 721.79 MiB | 29.43 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "From https://github.com/Skuldur/Classical-Piano-Composer\n",
            " * [new branch]      adding_support_for_files_with_no_parts -> origin/adding_support_for_files_with_no_parts\n",
            " * [new branch]      apply-pylint-to-codebase -> origin/apply-pylint-to-codebase\n",
            " * [new branch]      master               -> origin/master\n",
            " * [new branch]      no-data              -> origin/no-data\n",
            " * [new branch]      offsets_and_duration -> origin/offsets_and_duration\n",
            " * [new branch]      revert-19-master     -> origin/revert-19-master\n",
            " * [new branch]      varying_speed_notes  -> origin/varying_speed_notes\n",
            "fatal: ambiguous argument 'HEAD': unknown revision or path not in the working tree.\n",
            "Use '--' to separate paths from revisions, like this:\n",
            "'git <command> [<revision>...] -- [<file>...]'\n",
            "Removing .config/\n",
            "Removing sample_data/\n",
            "From https://github.com/Skuldur/Classical-Piano-Composer\n",
            " * branch            master     -> FETCH_HEAD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPgYZlcwzMS_",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Preparation\n",
        "\n",
        "The data is split into two objects. \n",
        "\n",
        "Notes, that contain information about:\n",
        "* Pitch: Frequency of the sound\n",
        "* Octave: Set of pitches\n",
        "* Offset: Where the note is located\n",
        "\n",
        "Chords, which are containers for a set of notes played at the same time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caIOKHmjxRpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data into an array\n",
        "notes = []\n",
        "for file in glob.glob(\"midi_songs/*.mid\"):\n",
        "\n",
        "    # Load file into a Music21 stream object\n",
        "    midi = converter.parse(file)\n",
        "\n",
        "    # Get a list of all notes and chords in the file\n",
        "    notes_to_parse = None\n",
        "    parts = instrument.partitionByInstrument(midi)\n",
        "    if parts: # File has instrument parts\n",
        "        notes_to_parse = parts.parts[0].recurse()\n",
        "    else: # File has notes in a flat structure\n",
        "        notes_to_parse = midi.flat.notes\n",
        "\n",
        "    # Append the pitch of every note object using its string notation\n",
        "    for element in notes_to_parse:\n",
        "        if isinstance(element, note.Note):\n",
        "            notes.append(str(element.pitch))\n",
        "        elif isinstance(element, chord.Chord):\n",
        "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "# Get amount of pitch names\n",
        "n_vocab = len(set(notes))\n",
        "\n",
        "# Each sequence can be this many notes/chords, to predict the next note in the sequence\n",
        "# the network will use this many previous notes to make the prediction. Worth trying\n",
        "# different sequence lengths\n",
        "sequence_length = 100\n",
        "\n",
        "# Get all pitch names\n",
        "pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "# Map pitches to integers\n",
        "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "network_input = []\n",
        "network_output = []\n",
        "\n",
        "# Create input sequences and corresponding outputs for the network\n",
        "for i in range(0, len(notes) - sequence_length, 1):\n",
        "    sequence_in = notes[i:i + sequence_length]\n",
        "    sequence_out = notes[i + sequence_length]\n",
        "    network_input.append([note_to_int[char] for char in sequence_in])\n",
        "    network_output.append(note_to_int[sequence_out])\n",
        "n_patterns = len(network_input)\n",
        "\n",
        "# Reshape the input into a format compatible with LSTM layers\n",
        "network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "\n",
        "# Normalise input\n",
        "network_input = network_input / float(n_vocab)\n",
        "network_output = to_categorical(network_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r45EnJ73NxU",
        "colab_type": "text"
      },
      "source": [
        "# LSTM Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6sypSVR3NR2",
        "colab_type": "code",
        "outputId": "87f3416a-73d8-4348-d486-73ea95101812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "# Input layer\n",
        "input = Input(shape=(network_input.shape[1], network_input.shape[2]))\n",
        "\n",
        "# Hidden layers\n",
        "layer = LSTM(256, return_sequences=True)(input)\n",
        "layer = Dropout(0.3)(layer)\n",
        "layer = LSTM(512, return_sequences=True)(layer)\n",
        "layer = Dropout(0.3)(layer)\n",
        "layer = LSTM(256)(layer)\n",
        "layer = Dense(256)(layer)\n",
        "layer = Dropout(0.3)(layer)\n",
        "layer = Dense(n_vocab)(layer)\n",
        "\n",
        "# Output layer\n",
        "output = Activation('softmax')(layer)\n",
        "\n",
        "# Compile model\n",
        "lstm = Model(input, output, name='lstm')\n",
        "lstm.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "lstm.summary()\n",
        "\n",
        "# Load the weights to each node\n",
        "# lstm.load_weights('weights.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100, 1)]          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 512)          1574912   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 256)               787456    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 358)               92006     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 358)               0         \n",
            "=================================================================\n",
            "Total params: 2,784,358\n",
            "Trainable params: 2,784,358\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFmrQs0W7XXD",
        "colab_type": "text"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2Ngq7k_5do9",
        "colab_type": "code",
        "outputId": "8a815ed1-354b-47c9-a83b-2a87bebae5e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = lstm.fit(network_input, network_output, epochs=50, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 4.6259\n",
            "Epoch 2/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 4.4981\n",
            "Epoch 3/50\n",
            "892/892 [==============================] - 113s 127ms/step - loss: 4.3959\n",
            "Epoch 4/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 4.2831\n",
            "Epoch 5/50\n",
            "892/892 [==============================] - 113s 127ms/step - loss: 4.1498\n",
            "Epoch 6/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 3.9773\n",
            "Epoch 7/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 3.7715\n",
            "Epoch 8/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 3.5438\n",
            "Epoch 9/50\n",
            "892/892 [==============================] - 111s 125ms/step - loss: 3.3189\n",
            "Epoch 10/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 3.1117\n",
            "Epoch 11/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 2.9258\n",
            "Epoch 12/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 2.7848\n",
            "Epoch 13/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 2.6456\n",
            "Epoch 14/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 2.4974\n",
            "Epoch 15/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 2.3690\n",
            "Epoch 16/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 2.2455\n",
            "Epoch 17/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 2.1195\n",
            "Epoch 18/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 2.0104\n",
            "Epoch 19/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 1.9164\n",
            "Epoch 20/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 1.8157\n",
            "Epoch 21/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 1.7315\n",
            "Epoch 22/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 1.6445\n",
            "Epoch 23/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 1.5635\n",
            "Epoch 24/50\n",
            "892/892 [==============================] - 113s 127ms/step - loss: 1.5037\n",
            "Epoch 25/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 1.4357\n",
            "Epoch 26/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 1.3821\n",
            "Epoch 27/50\n",
            "892/892 [==============================] - 113s 127ms/step - loss: 1.3295\n",
            "Epoch 28/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 1.2784\n",
            "Epoch 29/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 1.2342\n",
            "Epoch 30/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 1.1866\n",
            "Epoch 31/50\n",
            "892/892 [==============================] - 113s 127ms/step - loss: 1.1510\n",
            "Epoch 32/50\n",
            "892/892 [==============================] - 113s 127ms/step - loss: 1.1107\n",
            "Epoch 33/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 1.0859\n",
            "Epoch 34/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 1.0535\n",
            "Epoch 35/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 1.0154\n",
            "Epoch 36/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 0.9983\n",
            "Epoch 37/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 0.9649\n",
            "Epoch 38/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 0.9428\n",
            "Epoch 39/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 0.9275\n",
            "Epoch 40/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 0.9065\n",
            "Epoch 41/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 0.8864\n",
            "Epoch 42/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 0.8655\n",
            "Epoch 43/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 0.8553\n",
            "Epoch 44/50\n",
            "892/892 [==============================] - 113s 126ms/step - loss: 0.8382\n",
            "Epoch 45/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 0.8279\n",
            "Epoch 46/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 0.8080\n",
            "Epoch 47/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 0.7981\n",
            "Epoch 48/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 0.7842\n",
            "Epoch 49/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 0.7676\n",
            "Epoch 50/50\n",
            "892/892 [==============================] - 112s 126ms/step - loss: 0.7587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp87C21W3cva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_dir = \"output/models/\"\n",
        "\n",
        "# Save model structure\n",
        "model_json = lstm.to_json()\n",
        "with open(save_dir + \"music_lstm\" + \".json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# Save model weights\n",
        "lstm.save_weights(save_dir + \"music_lstm\" + \".h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYRK1o16PbcT",
        "colab_type": "text"
      },
      "source": [
        "# Generate Music"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQryRV73PWax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = numpy.random.randint(0, len(network_input)-1)\n",
        "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "pattern = network_input[start]\n",
        "prediction_output = []\n",
        "\n",
        "# Generate 500 notes\n",
        "for note_index in range(500):\n",
        "    prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    prediction_input = prediction_input / float(n_vocab)\n",
        "    prediction = model.predict(prediction_input, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = int_to_note[index]\n",
        "    prediction_output.append(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}