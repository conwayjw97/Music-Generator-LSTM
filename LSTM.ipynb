{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwM8VcbSX9dFte8iUnn5I0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conwayjw97/Music-Generator-LSTM/blob/master/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWllAAQIxXW5",
        "colab_type": "text"
      },
      "source": [
        "# [Tutorial Link](https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcWeBbDA4VQD",
        "colab_type": "text"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns6tg9sY4UuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "from music21 import converter, instrument, note, chord\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, Input\n",
        "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvA1gbK67qjZ",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z15jB5l27105",
        "colab_type": "code",
        "outputId": "4e103523-9fed-438b-baaa-66c9e759f2ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Initialise empty repository to pull data into\n",
        "!git init \n",
        "# Add the remote origin\n",
        "!git remote add origin -f https://github.com/Skuldur/Classical-Piano-Composer.git\n",
        "# Reset the HEAD in case a different folder was already pulled\n",
        "!git reset --hard HEAD\n",
        "!git clean -f -d\n",
        "# Tell git we are checking out specific folders\n",
        "!git config core.sparsecheckout true\n",
        "# Recursively checkout the needed folders\n",
        "!echo \"data/*\" >> .git/info/sparse-checkout\n",
        "!echo \"midi_songs/*\" >> .git/info/sparse-checkout\n",
        "!echo \"weights.hdf5\" >> .git/info/sparse-checkout\n",
        "# Pull dataset from repositoryF\n",
        "!git pull origin master"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "Updating origin\n",
            "remote: Enumerating objects: 334, done.\u001b[K\n",
            "remote: Total 334 (delta 0), reused 0 (delta 0), pack-reused 334\u001b[K\n",
            "Receiving objects: 100% (334/334), 721.79 MiB | 40.53 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "From https://github.com/Skuldur/Classical-Piano-Composer\n",
            " * [new branch]      adding_support_for_files_with_no_parts -> origin/adding_support_for_files_with_no_parts\n",
            " * [new branch]      apply-pylint-to-codebase -> origin/apply-pylint-to-codebase\n",
            " * [new branch]      master               -> origin/master\n",
            " * [new branch]      no-data              -> origin/no-data\n",
            " * [new branch]      offsets_and_duration -> origin/offsets_and_duration\n",
            " * [new branch]      revert-19-master     -> origin/revert-19-master\n",
            " * [new branch]      varying_speed_notes  -> origin/varying_speed_notes\n",
            "fatal: ambiguous argument 'HEAD': unknown revision or path not in the working tree.\n",
            "Use '--' to separate paths from revisions, like this:\n",
            "'git <command> [<revision>...] -- [<file>...]'\n",
            "Removing .config/\n",
            "Removing sample_data/\n",
            "From https://github.com/Skuldur/Classical-Piano-Composer\n",
            " * branch            master     -> FETCH_HEAD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPgYZlcwzMS_",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Preparation\n",
        "\n",
        "The data is split into two objects. \n",
        "\n",
        "Notes, that contain information about:\n",
        "* Pitch: Frequency of the sound\n",
        "* Octave: Set of pitches\n",
        "* Offset: Where the note is located\n",
        "\n",
        "Chords, which are containers for a set of notes played at the same time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caIOKHmjxRpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data into an array\n",
        "notes = []\n",
        "for file in glob.glob(\"midi_songs/*.mid\"):\n",
        "\n",
        "    # Load file into a Music21 stream object\n",
        "    midi = converter.parse(file)\n",
        "\n",
        "    # Get a list of all notes and chords in the file\n",
        "    notes_to_parse = None\n",
        "    parts = instrument.partitionByInstrument(midi)\n",
        "    if parts: # File has instrument parts\n",
        "        notes_to_parse = parts.parts[0].recurse()\n",
        "    else: # File has notes in a flat structure\n",
        "        notes_to_parse = midi.flat.notes\n",
        "\n",
        "    # Append the pitch of every note object using its string notation\n",
        "    for element in notes_to_parse:\n",
        "        if isinstance(element, note.Note):\n",
        "            notes.append(str(element.pitch))\n",
        "        elif isinstance(element, chord.Chord):\n",
        "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "# Get amount of pitch names\n",
        "n_vocab = len(set(notes))\n",
        "\n",
        "# Each sequence can be this many notes/chords, to predict the next note in the sequence\n",
        "# the network will use this many previous notes to make the prediction. Worth trying\n",
        "# different sequence lengths\n",
        "sequence_length = 100\n",
        "\n",
        "# Get all pitch names\n",
        "pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "# Map pitches to integers\n",
        "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "network_input = []\n",
        "network_output = []\n",
        "\n",
        "# Create input sequences and corresponding outputs for the network\n",
        "for i in range(0, len(notes) - sequence_length, 1):\n",
        "    sequence_in = notes[i:i + sequence_length]\n",
        "    sequence_out = notes[i + sequence_length]\n",
        "    network_input.append([note_to_int[char] for char in sequence_in])\n",
        "    network_output.append(note_to_int[sequence_out])\n",
        "n_patterns = len(network_input)\n",
        "\n",
        "# Reshape the input into a format compatible with LSTM layers\n",
        "network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "\n",
        "# Normalise input\n",
        "network_input = network_input / float(n_vocab)\n",
        "network_output = to_categorical(network_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r45EnJ73NxU",
        "colab_type": "text"
      },
      "source": [
        "# LSTM Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6sypSVR3NR2",
        "colab_type": "code",
        "outputId": "33e76073-6af5-4d5a-a834-0526bd5ff79d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "# Input layer\n",
        "input = Input(shape=(network_input.shape[1], network_input.shape[2]))\n",
        "\n",
        "# Hidden layers\n",
        "layer = LSTM(256, return_sequences=True)(input)\n",
        "layer = Dropout(0.3)(layer)\n",
        "layer = LSTM(512, return_sequences=True)(layer)\n",
        "layer = Dropout(0.3)(layer)\n",
        "layer = LSTM(256)(layer)\n",
        "layer = Dense(256)(layer)\n",
        "layer = Dropout(0.3)(layer)\n",
        "layer = Dense(n_vocab)(layer)\n",
        "\n",
        "# Output layer\n",
        "output = Activation('softmax')(layer)\n",
        "\n",
        "# Compile model\n",
        "lstm = Model(input, output, name='lstm')\n",
        "lstm.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "lstm.summary()\n",
        "\n",
        "# Load the weights to each node\n",
        "# lstm.load_weights('weights.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 100, 1)]          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100, 512)          1574912   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 256)               787456    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 358)               92006     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 358)               0         \n",
            "=================================================================\n",
            "Total params: 2,784,358\n",
            "Trainable params: 2,784,358\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFmrQs0W7XXD",
        "colab_type": "text"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2Ngq7k_5do9",
        "colab_type": "code",
        "outputId": "1c8967f7-dc0a-4e6b-95dd-6d48ef05b035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "history = lstm.fit(network_input, network_output, epochs=50, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "892/892 [==============================] - 115s 129ms/step - loss: 4.7091\n",
            "Epoch 2/50\n",
            "652/892 [====================>.........] - ETA: 30s - loss: 4.7086"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYRK1o16PbcT",
        "colab_type": "text"
      },
      "source": [
        "# Generate Music"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQryRV73PWax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}